import streamlit as st
from dotenv import load_dotenv
import os
from src.database import SupabaseManager
from src.embeddings import EmbeddingGenerator
from src.llm import LLMManager
from typing import List, Dict
import logging
from pathlib import Path

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
log_dir = Path(os.getenv("LOG_DIRECTORY", "logs"))
log_dir.mkdir(exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / 'app.log'),
        logging.StreamHandler()
    ]
)

# è¨€èªè¨­å®šç”¨ã®è¾æ›¸
TRANSLATIONS = {
    "en": {
        "title": "GDPR Guidelines Search",
        "search_settings": "Search Settings",
        "summary_threshold_label": "Summary Similarity Threshold",
        "summary_threshold_help": "Minimum similarity score for guideline summaries",
        "chunk_threshold_label": "Content Similarity Threshold",
        "chunk_threshold_help": "Minimum similarity score for content chunks",
        "recent_searches": "Recent Searches",
        "search_placeholder": "Enter your question about GDPR guidelines",
        "search_button": "Search",
        "searching": "Searching and generating response...",
        "question_label": "Question:",
        "answer_label": "Answer:",
        "referenced_guidelines": "Referenced Guidelines",
        "relevant_sections": "Relevant Sections",
        "version": "Version",
        "adopted": "Adopted",
        "type": "Type",
        "summary": "Summary",
        "show_context": "Show Full Context",
        "no_context": "No additional context available",
        "error": "An error occurred"
    },
    "ja": {
        "title": "GDPR ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æ¤œç´¢",
        "search_settings": "æ¤œç´¢è¨­å®š",
        "summary_threshold_label": "ã‚µãƒãƒªãƒ¼é¡ä¼¼åº¦é–¾å€¤",
        "summary_threshold_help": "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚µãƒãƒªãƒ¼ã®æœ€å°é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢",
        "chunk_threshold_label": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é¡ä¼¼åº¦é–¾å€¤",
        "chunk_threshold_help": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒ£ãƒ³ã‚¯ã®æœ€å°é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢",
        "recent_searches": "æœ€è¿‘ã®æ¤œç´¢",
        "search_placeholder": "GDPRã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«ã¤ã„ã¦ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        "search_button": "æ¤œç´¢",
        "searching": "æ¤œç´¢ä¸­ãƒ»å›ç­”ç”Ÿæˆï¿½ï¿½...",
        "question_label": "è³ªå•:",
        "answer_label": "å›ç­”:",
        "referenced_guidelines": "å‚ç…§ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
        "relevant_sections": "é–¢é€£ã‚»ã‚¯ã‚·ãƒ§ãƒ³",
        "version": "ãƒãƒ¼ã‚¸ãƒ§ãƒ³",
        "adopted": "æ¡æŠæ—¥",
        "type": "ç¨®é¡",
        "summary": "æ¦‚è¦",
        "show_context": "å…¨æ–‡è„ˆã‚’è¡¨ç¤º",
        "no_context": "è¿½åŠ ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“",
        "error": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    }
}

def initialize_managers():
    """ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–"""
    return (
        SupabaseManager(),
        EmbeddingGenerator(),
        LLMManager()
    )

def search_and_generate_response(
    query: str,
    db_manager: SupabaseManager,
    embedding_generator: EmbeddingGenerator,
    llm_manager: LLMManager,
    summary_threshold: float,
    chunk_threshold: float
) -> tuple[str, List[Dict], List[Dict], Dict]:
    """æ¤œç´¢ã¨å›ç­”ç”Ÿæˆã‚’å®Ÿè¡Œ"""
    try:
        # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
        query_embedding = embedding_generator.get_embedding(query)

        # ã‚µãƒãƒªãƒ¼æ¤œç´¢
        similar_summaries = db_manager.search_similar_summaries(
            query_embedding,
            threshold=summary_threshold
        )

        # ï¿½ï¿½ãƒ£ãƒ³ã‚¯æ¤œç´¢ï¼ˆã‚µãƒãƒªãƒ¼æ¤œç´¢ã®çµæœã‚’åˆ©ç”¨ï¼‰
        similar_chunks = db_manager.search_similar_chunks(
            query_embedding,
            guideline_matches=similar_summaries,
            threshold=chunk_threshold
        )
        
        # é–¾å€¤ã‚’è¶…ãˆã‚‹ãƒãƒ£ãƒ³ã‚¯ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_chunks = [chunk for chunk in similar_chunks if chunk['similarity'] >= chunk_threshold]

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        metadata = []
        guideline_titles = {}
        for summary in similar_summaries:
            meta = db_manager.get_guideline_metadata(
                summary['id'],
                similarity=summary['similarity']
            )
            if meta:
                metadata.append(meta)
                guideline_titles[summary['id']] = meta['title']

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆ
        response = llm_manager.generate_response(query, filtered_chunks, metadata)

        return response, metadata, filtered_chunks, guideline_titles

    except Exception as e:
        logging.error(f"Error in search_and_generate_response: {str(e)}")
        raise e

def main():
    # è¨€èªé¸æŠï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼‰
    if 'language' not in st.session_state:
        st.session_state.language = "en"
    if 'query_history' not in st.session_state:
        st.session_state.query_history = []

    # ç¾åœ¨ã®è¨€èªã®ç¿»è¨³ã‚’å–å¾—
    t = TRANSLATIONS[st.session_state.language]
    
    st.title(t["title"])
    
    # ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    db_manager, embedding_generator, llm_manager = initialize_managers()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
    with st.sidebar:
        # è¨€èªé¸æŠ
        st.selectbox(
            "Language / è¨€èª",
            ["English", "æ—¥æœ¬èª"],
            index=0 if st.session_state.language == "en" else 1,
            key="language_selector",
            on_change=lambda: setattr(
                st.session_state, 
                'language', 
                "en" if st.session_state.language_selector == "English" else "ja"
            )
        )
        
        st.header(t["search_settings"])
        
        summary_threshold = st.slider(
            t["summary_threshold_label"],
            min_value=0.0,
            max_value=1.0,
            value=0.4,
            step=0.05,
            help=t["summary_threshold_help"]
        )
        
        chunk_threshold = st.slider(
            t["chunk_threshold_label"],
            min_value=0.0,
            max_value=1.0,
            value=0.45,
            step=0.05,
            help=t["chunk_threshold_help"]
        )
        
        if st.session_state.query_history:
            st.markdown("---")
            st.markdown(f"**{t['recent_searches']}:**")
            for q in reversed(st.session_state.query_history):
                st.markdown(f"- {q}")

    query = st.text_area(
        "ğŸ” " + t["search_placeholder"],
        key="search_query",
        height=50
    )
    search_button = st.button("ğŸ” " + t["search_button"], disabled=not query)

    if search_button and query:
        if query not in st.session_state.query_history:
            st.session_state.query_history.append(query)
            if len(st.session_state.query_history) > 5:
                st.session_state.query_history.pop(0)
        
        try:
            with st.spinner(t["searching"]):
                response, metadata, context_chunks, guideline_titles = search_and_generate_response(
                    query,
                    db_manager,
                    embedding_generator,
                    llm_manager,
                    summary_threshold,
                    chunk_threshold
                )

                st.write("---")
                st.write(f"ğŸ¤” **{t['question_label']}**")
                st.write(query)
                st.write(f"ğŸ¤– **{t['answer_label']}**")
                st.write(response)

                st.write(f"ğŸ“š **{t['referenced_guidelines']}**")
                for summary in metadata:
                    with st.expander(f"**{summary['title']}** (Similarity: {summary['similarity']:.2f})"):
                        st.write(f"- {t['version']}: {summary['version']}")
                        st.write(f"- {t['adopted']}: {summary['adopted_date']}")
                        st.write(f"- {t['type']}: {summary['document_type']}")
                        st.write(f"#### {t['summary']}")
                        st.write(summary['summary'])

                st.write(f"ğŸ“„ **{t['relevant_sections']}**")
                sorted_chunks = sorted(context_chunks, key=lambda x: x['similarity'], reverse=True)

                # ä¸Šä½5å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã®ã¿ã‚’è¡¨ç¤º
                for i, chunk in enumerate(sorted_chunks[:5], 1):
                    if chunk['similarity'] < chunk_threshold:
                        continue
                    
                    guideline_title = guideline_titles.get(chunk['guideline_id'], "Unknown Guideline")
                    
                    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ©ãƒ³ã‚¯ä»˜ãè¡¨ç¤º
                    st.markdown(f"""
                    <div style='
                        border-left: 3px solid #e6e6e6;
                        padding-left: 15px;
                        margin-bottom: 5px;
                    '>
                        <div style='color: #666; margin-bottom: 10px;'>
                            <strong>#{i}</strong> | <strong>From: {guideline_title}</strong> (Similarity: {chunk['similarity']:.2f})
                        </div>
                        <p style='font-size: 1em; margin: 0 0 5px 0;'>{chunk['content']}</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒ³ã‚’ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«è¦–è¦šçš„ã«é–¢é€£ä»˜ã‘ã‚‹
                    st.markdown("""
                    <div style='
                        margin-left: 18px;
                        margin-bottom: 20px;
                        border-left: 3px solid #e6e6e6;
                    '>
                    """, unsafe_allow_html=True)
                    
                    with st.expander(f"ğŸ“– {t['show_context']}"):
                        context_chunks = chunk.get('context_chunks', [])
                        if not context_chunks:
                            st.write(t["no_context"])
                            continue
                        
                        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’é †åºä»˜ã‘ã¦å‡¦ç†
                        sorted_contexts = sorted(context_chunks, key=lambda x: x['chunk_id'])
                        combined_text = []
                        
                        for i, ctx in enumerate(sorted_contexts):
                            current_text = ctx['content']
                            
                            if ctx['chunk_id'] == chunk['id']:
                                # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ãã®ã¾ã¾è¡¨ç¤º
                                combined_text.append(f"<p style='font-size: 1em; margin: 10px 0;'>{current_text}</p>")
                            else:
                                # ã®ãƒãƒ£ãƒ³ã‚¯ã¨ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
                                if i > 0:
                                    prev_text = sorted_contexts[i-1]['content']
                                    overlap = find_overlap(prev_text, current_text)
                                    if overlap:
                                        current_text = current_text[len(overlap):]
                                
                                # æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã¨ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
                                if i < len(sorted_contexts) - 1:
                                    next_text = sorted_contexts[i+1]['content']
                                    overlap = find_overlap(current_text, next_text)
                                    if overlap:
                                        current_text = current_text[:-len(overlap)]
                                
                                combined_text.append(f"<p style='font-size: 1em; margin: 10px 0;'>{current_text}</p>")
                        
                        st.markdown("".join(combined_text), unsafe_allow_html=True)
                    
                    st.markdown("</div>", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"{t['error']}: {str(e)}")
            return

def find_overlap(text1: str, text2: str, min_length: int = 50) -> str:
    """2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆé–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’æ¤œå‡º"""
    # text1ã®æœ«å°¾ã¨text2ã®å…ˆé ­ã§æœ€é•·ã®å…±é€šéƒ¨åˆ†ã‚’æ¢ã™
    for length in range(min(len(text1), len(text2)), min_length - 1, -1):
        if text1[-length:] == text2[:length]:
            return text2[:length]
    return ""

if __name__ == "__main__":
    main()